# deep-learning-distilled
Notes on some important deep learning topics.</br>
Feel free to contribute.</br>
Accepting latex conversion of the documents.

### Notes added so far
* **Information, Entropy, Cross-Entropy: ML perspective:** Basic of information theory, why *log* is used to represent representation. entropy, cross entropy, KL divergence, likelihood, why cross wntropy loss is used in machine learning. 
* **Gradient Descent Optimizations:** Three gradient descent varients, chalenges with vanilla gradient descent, momentum, Nesterov accelerated gradient, Adagrad, RMSprop, Adadelta, Adam.

### Notes to add
- [ ] Regularization
- [ ] Linear algebra essentials
